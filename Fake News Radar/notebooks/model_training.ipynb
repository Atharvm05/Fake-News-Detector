{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection Model Training\n",
    "\n",
    "This notebook demonstrates how to train a fake news detection model using HuggingFace Transformers and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Dataset\n",
    "\n",
    "We'll use the LIAR dataset for this example. In a real implementation, you might want to combine multiple datasets like FakeNewsNet and LIAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# For demonstration, we'll create a simplified dataset loader\n",
    "# In a real implementation, you would load actual datasets\n",
    "\n",
    "def load_liar_dataset(data_dir):\n",
    "    # This is a placeholder for loading the LIAR dataset\n",
    "    # In reality, you would parse the actual LIAR dataset files\n",
    "    \n",
    "    # Create a sample dataframe for demonstration\n",
    "    data = {\n",
    "        'text': [\n",
    "            'The economy has improved significantly under the current administration.',\n",
    "            'Scientists have proven that climate change is a hoax.',\n",
    "            'The new healthcare bill will provide coverage to all citizens.',\n",
    "            'The government is putting chemicals in the water to control the population.',\n",
    "            'Vaccines have been linked to autism in multiple studies.'\n",
    "        ],\n",
    "        'label': [1, 0, 1, 0, 0]  # 1 for true, 0 for false\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Load dataset\n",
    "df = load_liar_dataset('data/')\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f'Training samples: {len(train_df)}')\n",
    "print(f'Validation samples: {len(val_df)}')\n",
    "print(f'Test samples: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load pre-trained tokenizer\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a custom dataset class\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension added by tokenizer\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        # Add label\n",
    "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return encoding\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NewsDataset(train_df['text'].tolist(), train_df['label'].tolist(), tokenizer)\n",
    "val_dataset = NewsDataset(val_df['text'].tolist(), val_df['label'].tolist(), tokenizer)\n",
    "test_dataset = NewsDataset(test_df['text'].tolist(), test_df['label'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Define metrics computation function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f'Test results: {test_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save model and tokenizer\n",
    "output_dir = '../backend/model/trained_model'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f'Model saved to {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test inference with a few examples\n",
    "test_texts = [\n",
    "    'The president signed a new executive order yesterday.',\n",
    "    'Scientists have discovered that the Earth is actually flat.',\n",
    "    'A new study shows that exercise can improve mental health.',\n",
    "    'The government is hiding aliens in Area 51.'\n",
    "]\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs = tokenizer(test_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "# Print results\n",
    "for i, text in enumerate(test_texts):\n",
    "    credibility_score = predictions[i, 1].item()  # Probability of being true\n",
    "    print(f'Text: {text}')\n",
    "    print(f'Credibility score: {credibility_score:.4f}')\n",
    "    \n",
    "    if credibility_score >= 0.7:\n",
    "        category = 'Credible'\n",
    "    elif credibility_score >= 0.4:\n",
    "        category = 'Somewhat Credible'\n",
    "    else:\n",
    "        category = 'Not Credible'\n",
    "        \n",
    "    print(f'Category: {category}\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates a basic approach to training a fake news detection model. In a real-world scenario, you would:\n",
    "\n",
    "1. Use larger and more diverse datasets\n",
    "2. Perform more extensive data preprocessing\n",
    "3. Experiment with different model architectures\n",
    "4. Implement more sophisticated evaluation metrics\n",
    "5. Add explainability features to highlight misleading content\n",
    "\n",
    "The trained model can then be integrated into the Fake News Radar application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}